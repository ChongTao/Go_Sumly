# 一 本地缓存

在服务开发中，**缓存（Cache）** 是提升性能最直接、最有效的手段之一。无论是数据库访问、接口调用，还是模型推理结果，只要数据存在重复请求，就可以通过缓存减少重复计算与 I/O。将数据直接缓存在当前进程的内存中，而非依赖外部系统（如 Redis、Memcached）的缓存方式。

## 1.1 本地缓存使用场景 

| 场景             | 示例                         |
| ---------------- | ---------------------------- |
| 🔍 热点数据缓存   | 热门商品、配置、用户信息     |
| 🚀 结果复用       | 下游接口响应、数据库查询结果 |
| ⚙️ 频繁计算结果   | 模型推理结果、指标聚合结果   |
| 🧩 短生命周期数据 | 临时 Token、限流标记         |

## 1.2 本地缓存好处 

| 优势                   | 说明                                       |
| ---------------------- | ------------------------------------------ |
| ⚡ **性能提升显著**     | 内存访问远快于网络访问（纳秒级 vs 毫秒级） |
| 💸 **减少外部依赖负载** | 缓解数据库或 Redis 压力                    |
| 🔒 **降低延迟与抖动**   | 本地读取避免网络波动                       |
| 🧠 **架构简化**         | 无需额外组件部署                           |
| 🧩 **灵活控制策略**     | 过期、淘汰策略可自定义实现                 |

## 1.3 本地缓存缺点 

| 缺点                   | 说明                           |
| ---------------------- | ------------------------------ |
| ❌ **进程隔离**         | 每个节点都有自己的缓存，不同步 |
| 🧹 **内存受限**         | 受进程内存限制，容易被 OOM     |
| ♻️ **一致性问题**       | 缓存更新、失效难以协调         |
| 🕒 **过期管理复杂**     | TTL 控制与清理逻辑需谨慎设计   |
| 🧩 **不适合大数据场景** | 仅适用于热点、小量高频访问数据 |

本地缓存适合**高频读、低变动、热点集中的数据**，而非全量或全局共享场景（这类应交给 Redis 等分布式存）。

# 二 Go基本实现 

Go 自带的并发工具足以实现一个简易缓存：`map + sync.RWMutex + time`。

```go
type Cache struct {
    data  map[string]item
    mu    sync.RWMutex
    ttl   time.Duration
}
type item struct {
    value      interface{}
    expiration int64
}

func NewCache(ttl time.Duration) *Cache {
    c := &Cache{data: make(map[string]item), ttl: ttl}
    go c.cleanup()
    return c
}

func (c *Cache) Set(key string, val interface{}) {
    c.mu.Lock()
    defer c.mu.Unlock()
    c.data[key] = item{val, time.Now().Add(c.ttl).UnixNano()}
}

func (c *Cache) Get(key string) (interface{}, bool) {
    c.mu.RLock()
    defer c.mu.RUnlock()
    it, ok := c.data[key]
    if !ok || time.Now().UnixNano() > it.expiration {
        return nil, false
    }
    return it.value, true
}

func (c *Cache) cleanup() {
    for {
        time.Sleep(c.ttl)
        now := time.Now().UnixNano()
        c.mu.Lock()
        for k, v := range c.data {
            if now > v.expiration {
                delete(c.data, k)
            }
        }
        c.mu.Unlock()
    }
}
```

上述在qps高场景下，就会出现锁竞争，而且缺少淘汰策略。

# 三 本地缓存开源框架

为了解决上述问题，Go 社区出现了一系列高性能、本地缓存专用库，常见增强点包括：

| 增强方向            | 说明                         |
| ------------------- | ---------------------------- |
| 🔒 分段锁 / 无锁结构 | 减少并发写入时的锁竞争       |
| ⏰ TTL 精细化        | 支持按 key 设置过期时间      |
| 🧠 淘汰策略          | LRU、LFU、TinyLFU 等智能策略 |
| 🧩 序列化优化        | 减少 GC 压力，提高内存利用率 |
| 💥 缓存击穿防护      | 避免大量请求同时穿透底层系统 |

主流 Go 本地缓存框架与使用情况：

| 框架                       | 特点                              | 典型场景               | 使用                          |
| -------------------------- | --------------------------------- | ---------------------- | ----------------------------- |
| **patrickmn/go-cache**     | 最早、最经典；支持 TTL + 定期清理 | 中小型服务             | [go-cache](./2 go-cache.md)   |
| **BigCache**               | 高并发安全；GC 友好；分片锁设计   | 高并发 Web 服务        | [BigCache](./3 BigCache.md)   |
| **FreeCache**              | lock-free；固定内存池；性能极高   | 性能敏感缓存场景       | [FreeCache](./3 FreeCache.md) |
| **Ristretto**              | TinyLFU 算法、智能淘汰策略        | 高频访问、高命中率要求 | [ristretto](./4 Ristretto.md) |
| **golang-lru (HashiCorp)** | 固定容量 LRU 缓存                 | 简单“最近最少使用”缓存 | `lru.New(128)`                |
| **bool64/cache**           | 支持泛型、懒加载、防击穿机制      | 缓存控制逻辑复杂的系统 | `cache.GetOrCreate(...)`      |

性能对比：

| 库                 | 写入 QPS   | 读取 QPS   | 内存占用 | GC 压力    |
| ------------------ | ---------- | ---------- | -------- | ---------- |
| `map+sync.RWMutex` | 中         | 中         | 高       | 高         |
| `go-cache`         | 中         | 中         | 中       | 高         |
| `FreeCache`        | 高         | 高         | 中       | 低         |
| **BigCache**       | 🚀 **极高** | 🚀 **极高** | 中       | ✅ **极低** |
| `Ristretto`        | 高         | 高         | 中       | 中         |